{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GETTING INFORMATION FROM AUTHORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import datetime\n",
    "from pydantic import HttpUrl\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pnytter import Pnytter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Author's list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_retweets = pd.read_csv('202503192044-AUTORES_RETWEETS_ETIQUETADOS_CONTAINS_HATE_TRUE.csv', index_col=None)\n",
    "df_retweets = df_retweets.rename(columns={'count_star()':'ocurrencias'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>ocurrencias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1694344217554776065</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714377328869171205</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4045996030</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1595358274647359490</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>902242545408905218</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author  ocurrencias\n",
       "0  1694344217554776065           94\n",
       "1   714377328869171205           19\n",
       "2           4045996030            8\n",
       "3  1595358274647359490            7\n",
       "4   902242545408905218            6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_retweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1458, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_retweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get the Author's information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Pnytter object needs at least 1 Nitter instance to work, but these can be added after initialization\n",
    "pnytter = Pnytter(\n",
    "  #nitter_instances=[\"http://localhost:8080\"]\n",
    "  nitter_instances=['https://xcancel.com',\n",
    " 'https://lightbrd.com',\n",
    " 'https://nitter.lucabased.xyz',\n",
    " 'https://nitter.space',\n",
    " 'https://nitter.net',\n",
    " 'https://nitter.privacyredirect.com',\n",
    " 'https://nitter.privacydev.net',\n",
    " 'https://nitter.poast.org',\n",
    " 'http://nitter.coffee2m3bjsrrqqycx6ghkxrnejl2q6nl7pjw2j4clchjj6uk5zozad.onion']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si partimos de datos ya descagados, estos han de estar en un fichero denominado **retweets_previo.csv** para seguir descargando datos a partir de estos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('retweets_previo.csv'):\n",
    "    df_anterior = pd.read_csv('retweets_previo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Buscando Retweets: 100%|██████████| 1776/1776 [00:57<00:00, 31.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos retweets.csv y errors.csv generados correctamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cont = 0\n",
    "\n",
    "data = {\n",
    "    'tweet_id': [],\n",
    "    'author': [],\n",
    "    'author_id': [],\n",
    "    'created_at': [],\n",
    "    'text': [],\n",
    "    'retweets_count': [], \n",
    "    'comments_count': [],\n",
    "    'likes_count': [],\n",
    "    'quotes_count': []\n",
    "}\n",
    "\n",
    "error = {\n",
    "    'tweet_id': [],\n",
    "}\n",
    "\n",
    "for row in tqdm(df_retweets.itertuples(), total=len(df_retweets), desc='Buscando Retweets'):\n",
    "    \n",
    "    # check if the tweet was already processed\n",
    "    if 'df_anterior' in locals():\n",
    "        if row.tweet_id in df_anterior.tweet_id.values:\n",
    "            cont += 1\n",
    "            continue\n",
    "\n",
    "    try:\n",
    "        tweet = pnytter.get_tweet(row.tweet_id)\n",
    "    except Exception as e:\n",
    "        cont += 1\n",
    "        #print(f\"Error al obtener el tweet {row.tweet_id}: {e}\")\n",
    "        error['tweet_id'].append(row.tweet_id)\n",
    "        continue\n",
    "\n",
    "    try: \n",
    "        data['author'].append(tweet.author) \n",
    "        data['created_at'].append(tweet.created_on)\n",
    "        data['text'].append(tweet.text)\n",
    "        data['retweets_count'].append(tweet.stats.retweets)\n",
    "        data['comments_count'].append(tweet.stats.comments)\n",
    "        data['likes_count'].append(tweet.stats.likes)\n",
    "        data['quotes_count'].append(tweet.stats.quotes)\n",
    "        data['tweet_id'].append(row.tweet_id)\n",
    "        data['author_id'].append(row.author)\n",
    "\n",
    "    except AttributeError:\n",
    "        error['tweet_id'].append(row.tweet_id)\n",
    "\n",
    "    cont += 1\n",
    "\n",
    "    if cont == 100:\n",
    "        cont = 0       \n",
    "        df = pd.DataFrame(data)\n",
    "        df_error = pd.DataFrame(error)\n",
    "        df.to_csv('retweets_temp.csv', index=False)\n",
    "        df_error.to_csv('errors_temp.csv', index=False)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df_error = pd.DataFrame(error)\n",
    "df.to_csv('retweets.csv', index=False)\n",
    "df_error.to_csv('errors.csv', index=False)\n",
    "print(\"Archivos retweets.csv y errors.csv generados correctamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat de retweets_previo y retweets\n",
    "\n",
    "Cómo hemos comentado anteriormente, si hemos partido de datos ya descargados, partiremos de retweets_previo, por eso hemos de hacer un concat de retweets_previo y retweets en retweets_final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('retweets_previo.csv'):\n",
    "    df_temp = pd.read_csv('retweets_previo.csv')\n",
    "    if os.path.exists('retweets.csv'):\n",
    "        df = pd.read_csv('retweets.csv')\n",
    "        df_final = pd.concat([df, df_temp], ignore_index=True)\n",
    "        df_final.to_csv('retweets_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos en retweets Previos: (1595, 9)\n",
      "Datos descargados en esta ejecución: (2, 9)\n",
      "Datos Totales: (1597, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"Datos en retweets Previos:\", df_temp.shape)\n",
    "print(\"Datos descargados en esta ejecución:\", df.shape)\n",
    "print(\"Datos Totales:\", df_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [tweet_id, author, author_id, created_at, text, retweets_count, comments_count, likes_count, quotes_count]\n",
      "Index: []\n",
      "Número de duplicatas: 0\n"
     ]
    }
   ],
   "source": [
    "# Verificar duplicatas em todas as colunas\n",
    "duplicated_rows = df_final[df_final.duplicated()]\n",
    "\n",
    "# Exibir as duplicatas\n",
    "print(duplicated_rows)\n",
    "\n",
    "# Contar o número de duplicatas\n",
    "print(f\"Número de duplicatas: {duplicated_rows.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [tweet_id, author, author_id, created_at, text, retweets_count, comments_count, likes_count, quotes_count]\n",
      "Index: []\n",
      "Número de duplicatas: 0\n"
     ]
    }
   ],
   "source": [
    "# Verificar duplicatas em todas as colunas\n",
    "duplicated_rows = df[df.duplicated()]\n",
    "\n",
    "# Exibir as duplicatas\n",
    "print(duplicated_rows)\n",
    "\n",
    "# Contar o número de duplicatas\n",
    "print(f\"Número de duplicatas: {duplicated_rows.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [tweet_id, author, author_id, created_at, text, retweets_count, comments_count, likes_count, quotes_count]\n",
      "Index: []\n",
      "Número de duplicatas: 0\n"
     ]
    }
   ],
   "source": [
    "# Verificar duplicatas em todas as colunas\n",
    "duplicated_rows = df_temp[df_temp.duplicated()]\n",
    "\n",
    "# Exibir as duplicatas\n",
    "print(duplicated_rows)\n",
    "\n",
    "# Contar o número de duplicatas\n",
    "print(f\"Número de duplicatas: {duplicated_rows.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borramos y renombramos los ficheros resultantes\n",
    "os.remove('retweets.csv')\n",
    "os.remove('retweets_previo.csv')\n",
    "os.rename('retweets_final.csv', 'retweets_previo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos Finales: (1597, 9)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('retweets_previo.csv')\n",
    "print(\"Datos Finales:\", df_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
