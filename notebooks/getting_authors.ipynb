{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GETTING INFORMATION FROM AUTHORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import datetime\n",
    "from pydantic import HttpUrl\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pnytter import Pnytter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Author's list\n",
    "\n",
    "Obtenemos esta lista, a partir de los datos de los retweets, obteniendo los autores únicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_retweets = pd.read_csv('retweets_previo.csv', index_col=None)\n",
    "df_retweets = df_retweets.rename(columns={'count_star()':'ocurrencias'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>comments_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>quotes_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1806254823139856439</td>\n",
       "      <td>rodrgue_carlos</td>\n",
       "      <td>1138440146</td>\n",
       "      <td>2024-06-27 09:14:00+00:00</td>\n",
       "      <td>Tienes que tener las rodillas en carne viva.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1805683330618474943</td>\n",
       "      <td>fernandovilabla</td>\n",
       "      <td>236524587</td>\n",
       "      <td>2024-06-25 19:23:00+00:00</td>\n",
       "      <td>Qué triste ser una arrastrada por un hijo medi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1807525208267305305</td>\n",
       "      <td>Jorge1941746303</td>\n",
       "      <td>1749504267092639745</td>\n",
       "      <td>2024-06-30 21:22:00+00:00</td>\n",
       "      <td>Un deseo le pido a la vida.. encontrarte por l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1807527629567738115</td>\n",
       "      <td>IKERERIK</td>\n",
       "      <td>348680194</td>\n",
       "      <td>2024-06-30 21:32:00+00:00</td>\n",
       "      <td>A ver tontin que han pasado de milagro</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1807479914624376932</td>\n",
       "      <td>michel38946321</td>\n",
       "      <td>1588948388204220421</td>\n",
       "      <td>2024-06-30 18:22:00+00:00</td>\n",
       "      <td>Estabas más callado que una movía y enseguida ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id           author            author_id  \\\n",
       "0  1806254823139856439   rodrgue_carlos           1138440146   \n",
       "1  1805683330618474943  fernandovilabla            236524587   \n",
       "2  1807525208267305305  Jorge1941746303  1749504267092639745   \n",
       "3  1807527629567738115         IKERERIK            348680194   \n",
       "4  1807479914624376932   michel38946321  1588948388204220421   \n",
       "\n",
       "                  created_at  \\\n",
       "0  2024-06-27 09:14:00+00:00   \n",
       "1  2024-06-25 19:23:00+00:00   \n",
       "2  2024-06-30 21:22:00+00:00   \n",
       "3  2024-06-30 21:32:00+00:00   \n",
       "4  2024-06-30 18:22:00+00:00   \n",
       "\n",
       "                                                text  retweets_count  \\\n",
       "0       Tienes que tener las rodillas en carne viva.               0   \n",
       "1  Qué triste ser una arrastrada por un hijo medi...               0   \n",
       "2  Un deseo le pido a la vida.. encontrarte por l...               0   \n",
       "3             A ver tontin que han pasado de milagro               0   \n",
       "4  Estabas más callado que una movía y enseguida ...               2   \n",
       "\n",
       "   comments_count  likes_count  quotes_count  \n",
       "0               0            0             0  \n",
       "1               0            1             0  \n",
       "2               0            0             0  \n",
       "3               0            0             0  \n",
       "4               0            3             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_retweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_authors = pd.DataFrame(df_retweets.author.value_counts()).reset_index()\n",
    "df_authors = df_authors.rename(columns={'count':'ocurrencias'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>ocurrencias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v66710974699714</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quinomartinez58</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agc_19827</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AE_HencheDiego</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lavanduardia012</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author  ocurrencias\n",
       "0  v66710974699714           94\n",
       "1  quinomartinez58           14\n",
       "2        Agc_19827            6\n",
       "3   AE_HencheDiego            6\n",
       "4  lavanduardia012            5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_authors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1325, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_authors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get the Author's information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remote server\n"
     ]
    }
   ],
   "source": [
    "localserver = False\n",
    "\n",
    "# The Pnytter object needs at least 1 Nitter instance to work, but these can be added after initialization\n",
    "if localserver: \n",
    "  pnytter = Pnytter(\n",
    "    nitter_instances=[\"http://localhost:8080\"]\n",
    "  )\n",
    "  print(\"Local server\")\n",
    "else:\n",
    "  pnytter = Pnytter(\n",
    "    nitter_instances=['https://xcancel.com',\n",
    "  'https://lightbrd.com',\n",
    "  'https://nitter.lucabased.xyz',\n",
    "  'https://nitter.space',\n",
    "  'https://nitter.net',\n",
    "  'https://nitter.privacyredirect.com',\n",
    "  'https://nitter.privacydev.net',\n",
    "  'https://nitter.poast.org',\n",
    "  'http://nitter.coffee2m3bjsrrqqycx6ghkxrnejl2q6nl7pjw2j4clchjj6uk5zozad.onion']\n",
    "  )\n",
    "  print(\"Remote server\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si partimos de datos ya descagados, estos han de estar en un fichero denominado **authors_previo.csv** para seguir descargando datos a partir de estos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('authors_previo.csv'):\n",
    "    df_anterior = pd.read_csv('authors_previo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Buscando Authors: 100%|██████████| 1325/1325 [09:15<00:00,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos authors.csv y errors_author.csv generados correctamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cont = 0\n",
    "\n",
    "data = {\n",
    "    'author_id': [],\n",
    "    'username': [],\n",
    "    'fullname': [],\n",
    "    'biography': [],\n",
    "    'verified': [],\n",
    "    'joined_datetime': [],\n",
    "    'tweets_count': [],\n",
    "    'following_count': [], \n",
    "    'followers_count': [],\n",
    "    'likes_count': [],\n",
    "    'profile_picture_url': [],\n",
    "    'banner_picture_url': []\n",
    "}\n",
    "\n",
    "error = {\n",
    "    'username': [],\n",
    "}\n",
    "\n",
    "for row in tqdm(df_authors.itertuples(), total=len(df_authors), desc='Buscando Authors'):\n",
    "    \n",
    "    # check if the tweet was already processed\n",
    "    if 'df_anterior' in locals():\n",
    "        if row.author in df_anterior.username.values:\n",
    "            cont += 1\n",
    "            continue\n",
    "\n",
    "    try:\n",
    "        user = pnytter.find_user(row.author) \n",
    "    except Exception as e:\n",
    "        cont += 1\n",
    "        #print(f\"Error al obtener el user {row.author}: {e}\")\n",
    "        error['username'].append(row.author)\n",
    "        continue\n",
    "\n",
    "    if not(user is None):\n",
    "\n",
    "        try: \n",
    "            if user.id != None:\n",
    "                data['author_id'].append(str(user.id)) \n",
    "            else:\n",
    "                data['author_id'].append(None)\n",
    "            data['fullname'].append(user.fullname)\n",
    "            data['biography'].append(user.biography)\n",
    "            data['verified'].append(user.verified)\n",
    "            if user.joined_datetime != None:\n",
    "                data['joined_datetime'].append(user.joined_datetime.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "            else:\n",
    "                data['joined_datetime'].append(None)\n",
    "            data['tweets_count'].append(user.stats.tweets)\n",
    "            data['following_count'].append(user.stats.following)\n",
    "            data['followers_count'].append(user.stats.followers)\n",
    "            data['likes_count'].append(user.stats.likes)\n",
    "            if user.pictures.profile != None:\n",
    "                data['profile_picture_url'].append(str(user.pictures.profile.twitter_url))\n",
    "            else:\n",
    "                data['profile_picture_url'].append(None)\n",
    "            if user.pictures.banner != None:\n",
    "                data['banner_picture_url'].append(str(user.pictures.banner.twitter_url))\n",
    "            else:\n",
    "                data['banner_picture_url'].append(None)\n",
    "            data['username'].append(row.author)\n",
    "\n",
    "        except AttributeError:\n",
    "            print(f\"Error al procesar el user {row.author}: {e}\")\n",
    "            error['username'].append(row.author)\n",
    "\n",
    "        cont += 1\n",
    "\n",
    "        if cont == 100:\n",
    "            cont = 0       \n",
    "            df = pd.DataFrame(data)\n",
    "            df_error = pd.DataFrame(error)\n",
    "            df.to_csv('authors_temp.csv', index=False)\n",
    "            df_error.to_csv('errors_author_temp.csv', index=False)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df_error = pd.DataFrame(error)\n",
    "df.to_csv('authors.csv', index=False)\n",
    "df_error.to_csv('errors_author.csv', index=False)\n",
    "print(\"Archivos authors.csv y errors_author.csv generados correctamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat de retweets_previo y retweets\n",
    "\n",
    "Cómo hemos comentado anteriormente, si hemos partido de datos ya descargados, partiremos de retweets_previo, por eso hemos de hacer un concat de retweets_previo y retweets en retweets_final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('authors_previo.csv'):\n",
    "    df_temp = pd.read_csv('authors_previo.csv')\n",
    "    if os.path.exists('authors.csv'):\n",
    "        df = pd.read_csv('authors.csv')\n",
    "        df_final = pd.concat([df, df_temp], ignore_index=True)\n",
    "        # Convert float to string without '.' or 'e'\n",
    "        df_final['author_id'] = df_final['author_id'].apply(lambda x: '{:.0f}'.format(x))\n",
    "        df_final['author_id'] = df_final['author_id'].astype(str)\n",
    "        df_final.to_csv('authors_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos en authors Previos: (741, 12)\n",
      "Datos descargados en esta ejecución: (59, 12)\n",
      "Datos Totales: (800, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Datos en authors Previos:\", df_temp.shape)\n",
    "print(\"Datos descargados en esta ejecución:\", df.shape)\n",
    "print(\"Datos Totales:\", df_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [author_id, username, fullname, biography, verified, joined_datetime, tweets_count, following_count, followers_count, likes_count, profile_picture_url, banner_picture_url]\n",
      "Index: []\n",
      "Número de duplicatas: 0\n"
     ]
    }
   ],
   "source": [
    "# Verificar duplicatas em todas as colunas\n",
    "duplicated_rows = df_final[df_final.duplicated()]\n",
    "\n",
    "# Exibir as duplicatas\n",
    "print(duplicated_rows)\n",
    "\n",
    "# Contar o número de duplicatas\n",
    "print(f\"Número de duplicatas: {duplicated_rows.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [author_id, username, fullname, biography, verified, joined_datetime, tweets_count, following_count, followers_count, likes_count, profile_picture_url, banner_picture_url]\n",
      "Index: []\n",
      "Número de duplicatas: 0\n"
     ]
    }
   ],
   "source": [
    "# Verificar duplicatas em todas as colunas\n",
    "duplicated_rows = df[df.duplicated()]\n",
    "\n",
    "# Exibir as duplicatas\n",
    "print(duplicated_rows)\n",
    "\n",
    "# Contar o número de duplicatas\n",
    "print(f\"Número de duplicatas: {duplicated_rows.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [author_id, username, fullname, biography, verified, joined_datetime, tweets_count, following_count, followers_count, likes_count, profile_picture_url, banner_picture_url]\n",
      "Index: []\n",
      "Número de duplicatas: 0\n"
     ]
    }
   ],
   "source": [
    "# Verificar duplicatas em todas as colunas\n",
    "duplicated_rows = df_temp[df_temp.duplicated()]\n",
    "\n",
    "# Exibir as duplicatas\n",
    "print(duplicated_rows)\n",
    "\n",
    "# Contar o número de duplicatas\n",
    "print(f\"Número de duplicatas: {duplicated_rows.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borramos y renombramos los ficheros resultantes\n",
    "os.remove('authors.csv')\n",
    "os.remove('authors_previo.csv')\n",
    "os.rename('authors_final.csv', 'authors_previo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos Finales: (800, 12)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('authors_previo.csv')\n",
    "print(\"Datos Finales:\", df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>username</th>\n",
       "      <th>fullname</th>\n",
       "      <th>biography</th>\n",
       "      <th>verified</th>\n",
       "      <th>joined_datetime</th>\n",
       "      <th>tweets_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>profile_picture_url</th>\n",
       "      <th>banner_picture_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.039863e+18</td>\n",
       "      <td>Alaiintxo</td>\n",
       "      <td>Alain</td>\n",
       "      <td>2024-04-06</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-09-12 13:05:00</td>\n",
       "      <td>5415</td>\n",
       "      <td>231</td>\n",
       "      <td>101</td>\n",
       "      <td>23598</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/186399114...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/10398625...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Neez1DJ</td>\n",
       "      <td>Padrellingham</td>\n",
       "      <td>Bruh, Vikingo de pura cepa</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-05-18 21:44:00</td>\n",
       "      <td>4232</td>\n",
       "      <td>285</td>\n",
       "      <td>55</td>\n",
       "      <td>16318</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/182970265...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.566592e+07</td>\n",
       "      <td>antoniogonpa</td>\n",
       "      <td>Tony 2009</td>\n",
       "      <td>Economista,Madridista, Antichavista se habla d...</td>\n",
       "      <td>True</td>\n",
       "      <td>2009-08-14 15:55:00</td>\n",
       "      <td>60866</td>\n",
       "      <td>2322</td>\n",
       "      <td>844</td>\n",
       "      <td>24184</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/378800000...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/65665921...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.102536e+08</td>\n",
       "      <td>Cantabriesque</td>\n",
       "      <td>Cantabriesque</td>\n",
       "      <td>This is the central scrutinizer...</td>\n",
       "      <td>True</td>\n",
       "      <td>2010-01-31 22:37:00</td>\n",
       "      <td>7017</td>\n",
       "      <td>1057</td>\n",
       "      <td>194</td>\n",
       "      <td>23946</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/151054214...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/11025362...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>TheMutterficker</td>\n",
       "      <td>The Mutterficker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2012-07-19 14:54:00</td>\n",
       "      <td>29819</td>\n",
       "      <td>1146</td>\n",
       "      <td>138</td>\n",
       "      <td>18268</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/111200184...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      author_id         username          fullname  \\\n",
       "0  1.039863e+18        Alaiintxo             Alain   \n",
       "1           NaN          Neez1DJ     Padrellingham   \n",
       "2  6.566592e+07     antoniogonpa         Tony 2009   \n",
       "3  1.102536e+08    Cantabriesque     Cantabriesque   \n",
       "4           NaN  TheMutterficker  The Mutterficker   \n",
       "\n",
       "                                           biography  verified  \\\n",
       "0                                         2024-04-06      True   \n",
       "1                         Bruh, Vikingo de pura cepa      True   \n",
       "2  Economista,Madridista, Antichavista se habla d...      True   \n",
       "3                 This is the central scrutinizer...      True   \n",
       "4                                                NaN      True   \n",
       "\n",
       "       joined_datetime  tweets_count  following_count  followers_count  \\\n",
       "0  2018-09-12 13:05:00          5415              231              101   \n",
       "1  2022-05-18 21:44:00          4232              285               55   \n",
       "2  2009-08-14 15:55:00         60866             2322              844   \n",
       "3  2010-01-31 22:37:00          7017             1057              194   \n",
       "4  2012-07-19 14:54:00         29819             1146              138   \n",
       "\n",
       "   likes_count                                profile_picture_url  \\\n",
       "0        23598  https://pbs.twimg.com/profile_images/186399114...   \n",
       "1        16318  https://pbs.twimg.com/profile_images/182970265...   \n",
       "2        24184  https://pbs.twimg.com/profile_images/378800000...   \n",
       "3        23946  https://pbs.twimg.com/profile_images/151054214...   \n",
       "4        18268  https://pbs.twimg.com/profile_images/111200184...   \n",
       "\n",
       "                                  banner_picture_url  \n",
       "0  https://pbs.twimg.com/profile_banners/10398625...  \n",
       "1                                                NaN  \n",
       "2  https://pbs.twimg.com/profile_banners/65665921...  \n",
       "3  https://pbs.twimg.com/profile_banners/11025362...  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
