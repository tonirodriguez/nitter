{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GETTING INFORMATION FROM AUTHORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import datetime\n",
    "from pydantic import HttpUrl\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pnytter import Pnytter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Author's list\n",
    "\n",
    "Obtenemos esta lista, a partir de los datos de los retweets, obteniendo los autores únicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_retweets = pd.read_csv('retweets_previo.csv', index_col=None)\n",
    "df_retweets = df_retweets.rename(columns={'count_star()':'ocurrencias'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>comments_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>quotes_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1806254823139856439</td>\n",
       "      <td>rodrgue_carlos</td>\n",
       "      <td>1138440146</td>\n",
       "      <td>2024-06-27 09:14:00+00:00</td>\n",
       "      <td>Tienes que tener las rodillas en carne viva.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1805683330618474943</td>\n",
       "      <td>fernandovilabla</td>\n",
       "      <td>236524587</td>\n",
       "      <td>2024-06-25 19:23:00+00:00</td>\n",
       "      <td>Qué triste ser una arrastrada por un hijo medi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1807525208267305305</td>\n",
       "      <td>Jorge1941746303</td>\n",
       "      <td>1749504267092639745</td>\n",
       "      <td>2024-06-30 21:22:00+00:00</td>\n",
       "      <td>Un deseo le pido a la vida.. encontrarte por l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1807527629567738115</td>\n",
       "      <td>IKERERIK</td>\n",
       "      <td>348680194</td>\n",
       "      <td>2024-06-30 21:32:00+00:00</td>\n",
       "      <td>A ver tontin que han pasado de milagro</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1807479914624376932</td>\n",
       "      <td>michel38946321</td>\n",
       "      <td>1588948388204220421</td>\n",
       "      <td>2024-06-30 18:22:00+00:00</td>\n",
       "      <td>Estabas más callado que una movía y enseguida ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id           author            author_id  \\\n",
       "0  1806254823139856439   rodrgue_carlos           1138440146   \n",
       "1  1805683330618474943  fernandovilabla            236524587   \n",
       "2  1807525208267305305  Jorge1941746303  1749504267092639745   \n",
       "3  1807527629567738115         IKERERIK            348680194   \n",
       "4  1807479914624376932   michel38946321  1588948388204220421   \n",
       "\n",
       "                  created_at  \\\n",
       "0  2024-06-27 09:14:00+00:00   \n",
       "1  2024-06-25 19:23:00+00:00   \n",
       "2  2024-06-30 21:22:00+00:00   \n",
       "3  2024-06-30 21:32:00+00:00   \n",
       "4  2024-06-30 18:22:00+00:00   \n",
       "\n",
       "                                                text  retweets_count  \\\n",
       "0       Tienes que tener las rodillas en carne viva.               0   \n",
       "1  Qué triste ser una arrastrada por un hijo medi...               0   \n",
       "2  Un deseo le pido a la vida.. encontrarte por l...               0   \n",
       "3             A ver tontin que han pasado de milagro               0   \n",
       "4  Estabas más callado que una movía y enseguida ...               2   \n",
       "\n",
       "   comments_count  likes_count  quotes_count  \n",
       "0               0            0             0  \n",
       "1               0            1             0  \n",
       "2               0            0             0  \n",
       "3               0            0             0  \n",
       "4               0            3             0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_retweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_authors = pd.DataFrame(df_retweets.author.value_counts()).reset_index()\n",
    "df_authors = df_authors.rename(columns={'count':'ocurrencias'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>ocurrencias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v66710974699714</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quinomartinez58</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agc_19827</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AE_HencheDiego</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lavanduardia012</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author  ocurrencias\n",
       "0  v66710974699714           94\n",
       "1  quinomartinez58           14\n",
       "2        Agc_19827            6\n",
       "3   AE_HencheDiego            6\n",
       "4  lavanduardia012            5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_authors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1325, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_authors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get the Author's information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local server\n"
     ]
    }
   ],
   "source": [
    "localserver = True\n",
    "\n",
    "# The Pnytter object needs at least 1 Nitter instance to work, but these can be added after initialization\n",
    "if localserver: \n",
    "  pnytter = Pnytter(\n",
    "    nitter_instances=[\"http://localhost:8080\"]\n",
    "  )\n",
    "  print(\"Local server\")\n",
    "else:\n",
    "  pnytter = Pnytter(\n",
    "    nitter_instances=['https://xcancel.com',\n",
    "  'https://lightbrd.com',\n",
    "  'https://nitter.lucabased.xyz',\n",
    "  'https://nitter.space',\n",
    "  'https://nitter.net',\n",
    "  'https://nitter.privacyredirect.com',\n",
    "  'https://nitter.privacydev.net',\n",
    "  'https://nitter.poast.org',\n",
    "  'http://nitter.coffee2m3bjsrrqqycx6ghkxrnejl2q6nl7pjw2j4clchjj6uk5zozad.onion']\n",
    "  )\n",
    "  print(\"Remote server\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si partimos de datos ya descagados, estos han de estar en un fichero denominado **authors_previo.csv** para seguir descargando datos a partir de estos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('authors_previo.csv'):\n",
    "    df_anterior = pd.read_csv('authors_previo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Buscando Authors:   0%|          | 0/1325 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Buscando Authors: 100%|██████████| 1325/1325 [00:14<00:00, 90.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos authors.csv y errors_author.csv generados correctamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cont = 0\n",
    "\n",
    "data = {\n",
    "    'author_id': [],\n",
    "    'username': [],\n",
    "    'fullname': [],\n",
    "    'biography': [],\n",
    "    'verified': [],\n",
    "    'joined_datetime': [],\n",
    "    'tweets_count': [],\n",
    "    'following_count': [], \n",
    "    'followers_count': [],\n",
    "    'likes_count': [],\n",
    "    'profile_picture_url': [],\n",
    "    'banner_picture_url': []\n",
    "}\n",
    "\n",
    "error = {\n",
    "    'username': [],\n",
    "}\n",
    "\n",
    "for row in tqdm(df_authors.itertuples(), total=len(df_authors), desc='Buscando Authors'):\n",
    "    \n",
    "    # check if the tweet was already processed\n",
    "    if 'df_anterior' in locals():\n",
    "        if row.author in df_anterior.username.values:\n",
    "            cont += 1\n",
    "            continue\n",
    "\n",
    "    try:\n",
    "        user = pnytter.find_user(row.author) \n",
    "    except Exception as e:\n",
    "        cont += 1\n",
    "        #print(f\"Error al obtener el user {row.author}: {e}\")\n",
    "        error['username'].append(row.author)\n",
    "        continue\n",
    "\n",
    "    if not(user is None):\n",
    "\n",
    "        try: \n",
    "            data['author_id'].append(user.id) \n",
    "            data['fullname'].append(user.fullname)\n",
    "            data['biography'].append(user.biography)\n",
    "            data['verified'].append(user.verified)\n",
    "            if user.joined_datetime != None:\n",
    "                data['joined_datetime'].append(user.joined_datetime.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "            else:\n",
    "                data['joined_datetime'].append(None)\n",
    "            data['tweets_count'].append(user.stats.tweets)\n",
    "            data['following_count'].append(user.stats.following)\n",
    "            data['followers_count'].append(user.stats.followers)\n",
    "            data['likes_count'].append(user.stats.likes)\n",
    "            if user.pictures.profile != None:\n",
    "                data['profile_picture_url'].append(str(user.pictures.profile.twitter_url))\n",
    "            else:\n",
    "                data['profile_picture_url'].append(None)\n",
    "            if user.pictures.banner != None:\n",
    "                data['banner_picture_url'].append(str(user.pictures.banner.twitter_url))\n",
    "            else:\n",
    "                data['banner_picture_url'].append(None)\n",
    "            data['username'].append(row.author)\n",
    "\n",
    "        except AttributeError:\n",
    "            print(f\"Error al procesar el user {row.author}: {e}\")\n",
    "            error['username'].append(row.author)\n",
    "\n",
    "        cont += 1\n",
    "\n",
    "        if cont == 100:\n",
    "            cont = 0       \n",
    "            df = pd.DataFrame(data)\n",
    "            df_error = pd.DataFrame(error)\n",
    "            df.to_csv('authors_temp.csv', index=False)\n",
    "            df_error.to_csv('errors_author_temp.csv', index=False)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df_error = pd.DataFrame(error)\n",
    "df.to_csv('authors.csv', index=False)\n",
    "df_error.to_csv('errors_author.csv', index=False)\n",
    "print(\"Archivos authors.csv y errors_author.csv generados correctamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat de retweets_previo y retweets\n",
    "\n",
    "Cómo hemos comentado anteriormente, si hemos partido de datos ya descargados, partiremos de retweets_previo, por eso hemos de hacer un concat de retweets_previo y retweets en retweets_final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('authors_previo.csv'):\n",
    "    df_temp = pd.read_csv('authors_previo.csv')\n",
    "    if os.path.exists('authors.csv'):\n",
    "        df = pd.read_csv('authors.csv')\n",
    "        df_final = pd.concat([df, df_temp], ignore_index=True)\n",
    "        df_final.to_csv('authors_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos en authors Previos: (1320, 12)\n",
      "Datos descargados en esta ejecución: (5, 12)\n",
      "Datos Totales: (1325, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Datos en authors Previos:\", df_temp.shape)\n",
    "print(\"Datos descargados en esta ejecución:\", df.shape)\n",
    "print(\"Datos Totales:\", df_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [author_id, username, fullname, biography, verified, joined_datetime, tweets_count, following_count, followers_count, likes_count, profile_picture_url, banner_picture_url]\n",
      "Index: []\n",
      "Número de duplicatas: 0\n"
     ]
    }
   ],
   "source": [
    "# Verificar duplicatas em todas as colunas\n",
    "duplicated_rows = df_final[df_final.duplicated()]\n",
    "\n",
    "# Exibir as duplicatas\n",
    "print(duplicated_rows)\n",
    "\n",
    "# Contar o número de duplicatas\n",
    "print(f\"Número de duplicatas: {duplicated_rows.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [author_id, username, fullname, biography, verified, joined_datetime, tweets_count, following_count, followers_count, likes_count, profile_picture_url, banner_picture_url]\n",
      "Index: []\n",
      "Número de duplicatas: 0\n"
     ]
    }
   ],
   "source": [
    "# Verificar duplicatas em todas as colunas\n",
    "duplicated_rows = df[df.duplicated()]\n",
    "\n",
    "# Exibir as duplicatas\n",
    "print(duplicated_rows)\n",
    "\n",
    "# Contar o número de duplicatas\n",
    "print(f\"Número de duplicatas: {duplicated_rows.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [author_id, username, fullname, biography, verified, joined_datetime, tweets_count, following_count, followers_count, likes_count, profile_picture_url, banner_picture_url]\n",
      "Index: []\n",
      "Número de duplicatas: 0\n"
     ]
    }
   ],
   "source": [
    "# Verificar duplicatas em todas as colunas\n",
    "duplicated_rows = df_temp[df_temp.duplicated()]\n",
    "\n",
    "# Exibir as duplicatas\n",
    "print(duplicated_rows)\n",
    "\n",
    "# Contar o número de duplicatas\n",
    "print(f\"Número de duplicatas: {duplicated_rows.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borramos y renombramos los ficheros resultantes\n",
    "os.remove('authors.csv')\n",
    "os.remove('authors_previo.csv')\n",
    "os.rename('authors_final.csv', 'authors_previo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos Finales: (1325, 12)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('authors_previo.csv')\n",
    "print(\"Datos Finales:\", df_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
